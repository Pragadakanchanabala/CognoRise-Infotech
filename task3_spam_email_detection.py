# -*- coding: utf-8 -*-
"""Task3-Spam Email Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eCFuV8m9CQqoz9IJ6SuCtCWXsyyKAdzW

##SPAM EMAIL DETECTION

Dataset contains 5572 rows and 2 independent features.

Output:

Category: This column helps to predict whether the email message is spam or not.

**Data Loading**
"""

import numpy as np
import pandas as pd
import nltk
import re
import matplotlib.pyplot as plt
import seaborn as sns
df=pd.read_csv('C:/Users/praga/Downloads/CognoRise-main/CognoRise-main/spam.csv')
df

df.head()

df.tail()

"""**Preprocessing Steps**"""

df['Category'].value_counts()

sns.countplot(x='Category',data=df)

df['Category']=df['Category'].map({'ham':0,'spam':1})
df

df.columns

df.isna().sum()

df.dtypes

email=df.Message
email

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')

from nltk.tokenize import TweetTokenizer
tk=TweetTokenizer()
email=email.apply(lambda x:tk.tokenize(x)).apply(lambda x:" ".join(x))
email

email=email.str.replace('[^a-zA-Z0-9+]',' ') #+ ==>####
email

"""**Tokenization**"""

from nltk.tokenize import word_tokenize
email=email.apply(lambda x:' '.join([w for w in word_tokenize(x) if len(w)>=3]))
email

"""**Stemming**"""

from nltk.stem import SnowballStemmer
stemmer=SnowballStemmer('english')
email=email.apply(lambda x:[stemmer.stem(i.lower()) for i in tk.tokenize(x)]).apply(lambda x:" ".join(x))
email

from nltk.corpus import stopwords
sw=stopwords.words('english')
email=email.apply(lambda x:[i for i in tk.tokenize(x) if i not in sw]).apply(lambda x:" ".join(x))
email

"""**Vectorization**"""

from sklearn.feature_extraction.text import TfidfVectorizer
vec=TfidfVectorizer()
train_data=vec.fit_transform(email)
train_data

train_data.shape

y=df['Category'].values
y

"""**Train Test Split**"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(train_data,y,test_size=0.30,random_state=42)
x_train

"""**Model Creation**"""

from sklearn.neighbors import KNeighborsClassifier
model1=KNeighborsClassifier(n_neighbors=7)
from sklearn.ensemble import RandomForestClassifier
model2=RandomForestClassifier(n_estimators=100,criterion='entropy',random_state=42)
lst=[model1,model2]
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,ConfusionMatrixDisplay

"""**Performance Evaluation**"""

for i in lst:
  i.fit(x_train,y_train)
  y_pred=i.predict(x_test)
  print(y_pred)
  print('score=',accuracy_score(y_test,y_pred))
  print('Report:',classification_report(y_test,y_pred))
  print('matrix:',confusion_matrix(y_test,y_pred))
  print('-'*100)

lab=['ham','spam']
cm=confusion_matrix(y_test,y_pred)
cmd=ConfusionMatrixDisplay(cm,display_labels=lab)
cmd.plot()
